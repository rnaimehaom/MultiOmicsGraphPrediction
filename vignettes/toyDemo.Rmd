
---
title: "Ensemble Toy Demo"
author: "Tara Eicher"
date: "2/22/2022"
output: rmarkdown::html_document
vignette: >
  %\VignetteIndexEntry{MultiOmicsGraphPrediction Toy}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---
# Description
This toy example was created to verify that the proposed ensemble neural network performs as expected.
It includes patients P1-P6, metabolites M1-M6, and genes G1-G11.

In this example, age is the predicted phenotype, and artificial gene and metabolite values have been
created as follows:
- M2 = M1 * age / 2
- M3 = M1 / age
- M4 = -M2 / age
- G4 = -M2 / age
- G6 = -M2 / age
- G7 = M1 / age
- G8 = -M2 / age
- G11 = M1 / age

All other gene and metabolite data were filled in using a random number between
-1 and 1.

We therefore know that age can be predicted using the following predictive models that are in the
form used by our model:
- age = -1 * M2 / G4, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -1
- age = -1 * M2 / G6, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -1
- age = -1 * M2 / G8, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -1
- age = M1 / G7, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = 1
- age = M1 / G11, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = 1
- age = -2 * M4 / G7, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -0.5
- age = -2 * M4 / G11, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -0.5

The following analyte models also exist but are not predictive of age:
- M3 = G7, i.e. beta0 = 0, beta1 = 1, beta2 = 0, and beta3 = 0
- M3 = G11, i.e. beta0 = 0, beta2 = 1, beta3 = 0, and beta3 = 0

We expect to see the final predictive subgraph comprised of one or more of the predictive models
listed above and not include any of the non-predictive models.

# Set up.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
result_dir <- "~\\Ensemble_toy_vignette_results"
dir.create(result_dir)
```

# Install the packages.
```{r eval = FALSE}
if(!require("devtools")){
  install.packages("devtools")
}
library("devtools")
if(!require("MultiOmicsGraphPrediction")){
  install_github("ncats/MultiOmicsGraphPrediction")
}
library(MultiOmicsGraphPrediction)
if(!require("IntLIM")){
  install_github("ncats/IntLIM")
}
library(IntLIM)
```

# Import Toy data files.
```{r}
dir <- system.file("extdata", package="MultiOmicsGraphPrediction", mustWork=TRUE)
csvfile <- file.path(dir, "toyinput.csv")
inputData <- IntLIM::ReadData(csvfile)
```

# Run IntLIM
We note that the following models are learned as expected:
- M2 = 0 + 0 * G4 + 0 * age + -1 * G4 * age
- M2 = 0 + 0 * G6 + 0 * age + -1 * G6 * age
- M2 = 0 + 0 * G8 + 0 * age + -1 * G8 * age
- M4 = 0 - 0 * G7 - 0 * age -0.5 * G7 * age
- M4 = 0 - 0 * G11 - 0 * age -0.5 * G11 * age
- M1 = 0 + 0 * G7 + 0 * age + 1 * G7 * age
- M1 = 0 + 0 * G11 + 0 * age + 1 * G7 * age
- M3 = 0 + 1 * G7 - 0 * age + 0 * G7 * age
- M3 = 0 + 1 * G11 - 0 * age + 0 * G7 * age
```{r}
myres <- IntLIM::RunIntLim(inputData = inputData,stype="age",
                                 save.covar.pvals = TRUE, 
                                 outcome = 1, 
                                 independent.var.type = 2, 
                                 continuous = TRUE)
View(myres@covariate.coefficients)
```

# Filter Results and Create Co-Regulation Graph
The expected pairs all pass the R^2 threshold.

Other pairs that also pass the threshold are:
(M1, G10)
(M2, [G7, G10, G11])
(M3, [G3, G4, G6, G8, G10])
(M4, [G3, G4, G6, G8, G10])
```{r}
myres.all <- IntLIM::ProcessResults(inputResults = myres, inputData = inputData, 
                                       pvalcutoff = 1, rsquaredCutoff = 0, interactionCoeffPercentile = 0)
myres.r2.density <- density(myres.all$rsquared)
peak.r2 <- myres.r2.density$x[which.max(myres.r2.density$y)]
myres.r2 <- IntLIM::ProcessResults(inputResults = myres, inputData = inputData, 
                                       pvalcutoff = 1, rsquaredCutoff = peak.r2)
# Build graph.
coreg.r2 <- MultiOmicsGraphPrediction::BuildCoRegulationGraph(myres.r2)
MultiOmicsGraphPrediction::PlotCoRegulationGraph(coreg.r2, "", saveInFile = NULL, vertices = NULL)
View(myres.r2)
```

# Run Pairwise Prediction.
We can see that the predictions are exactly correct for (M2, [G4, G6, G8]), 
(M4, [G7, G11]), and (M1, [G7, G11]). Some of the other
pairs also give close predictions. The predictions given by (M3, [G7, G11])
are not correct, which is expected because their relationship does not
depend on age.
```{r}
# Run pairwise prediction.
pred <- MultiOmicsGraphPrediction::RunPairwisePrediction(inputResults = myres.r2, 
                                                         inputData = inputData,
                                                         stype = "age",
                                                         independentVarType = 2,
                                                         outcomeType = 1)
hist(pred, breaks = 100)
print(inputData@sampleMetaData[,"age"])
print(pred)
```

## Project Predictions
```{r plot graph}
# Project graph.
projectedGraph <- MultiOmicsGraphPrediction::ProjectPredictionsOntoGraph(coRegulationGraph = coreg.r2,
                                                                         predictions = pred)
MultiOmicsGraphPrediction::PlotGraphPredictions(graph = projectedGraph,
                                                inputData = inputData,
                                                stype = "age")
```

## Compute Importance Metrics.
In this case, the subspace grouping of patients has little relationship to the phenotype.
However, this is likely due to the analyte values being assigned randomly.

Regarding importance metrics, the exact predictors do not have notably higher PDF scores
than the other predictors. However, the local error importance values are higher for the
exact predictors than the other predictors, as are the interaction p-value importance scores.
```{r importance}
MultiOmicsGraphPrediction::PlotSubspaceClusteringDendrogram(inputData = inputData, eigStep = 1)
MultiOmicsGraphPrediction::PlotSubspaceClusteringHeatmap(inputData = inputData, eigStep = 1)
metaFeatures <- MultiOmicsGraphPrediction::GetMetaFeatures(predictions = pred, 
                                                                 stype = "age",
                                                                 inputData = inputData, 
                                                                 metaFeatureList = c("pdf", "interactionpval", "interactioncoef", "analytecoef", "localerr"),
                                                                 k = 2, eigStep = 1,
                                                                 modelStats = myres.r2,
                                                                 colIdInd = "databaseId",
                                                                 colIdOut = "databaseId")
hist(metaFeatures$pdf)
hist(metaFeatures$localerr)
hist(metaFeatures$interactionpval)
hist(metaFeatures$interactioncoef)
hist(metaFeatures$analytecoef)
print(metaFeatures)
```

# Look at a predictive model.
## Stringent cutoff
- age = -1 * M2 / G4, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -1
- age = -1 * M2 / G6, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -1
- age = -1 * M2 / G8, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -1
- age = M1 / G7, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = 1
- age = M1 / G11, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = 1
- age = -2 * M4 / G7, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -0.5
- age = -2 * M4 / G11, i.e. beta0 = 0, beta1 = 0, beta2 = 0, and beta3 = -0.5

In this example, we use the t-score of the predicted values to determine whether
or not to keep each model. We use a stringent model retention strategy, keeping
only models that improve the overall score (not those that neither improve nor
reduce the score).

The M2-based predictors are grouped together with G4 predictors in neighborhood 1.
In neighborhood 1, all predictors are removed except (M2, G4), an exact predictor.

The M4-based predictors are grouped together in neighborhood 2, along with the G7 predictors.
In neighborhood 2, all predictors are removed except (M4, G7), another exact predictor.

The M3-based predictors are grouped together in neighborhood 3.
In neighborhood 3, all predictors are removed except (M3, [G6, G8]) and (M6, G3).

The M1-based predictors are grouped together with G4 predictors in neighborhood 4.
In neighborhood 4, all predictors are removed except (M2, G4).

In the second iteration, neighborhoods 1 and 4 are combined to create the new neighborhood 1, and nothing is removed
(because they are identical). Nothing is removed from the other neighborhoods.

In the third iteration, neighborhoods 1 and 2 are combined to create the new neighborhood 1,
but neighborhood 2 is removed because both represent exact predictors. Neighborhood
3 becomes neighborhood 2.

In the fourth iteration, neighborhoods 1 and 2 are combined to create the new neighborhood 1,
but neighborhood 2 is removed so that only the exact predictor remains.

The single pair (M2, G4) gives an exact prediction for the entire data set as expected.
```{r}
modelInput <- MultiOmicsGraphPrediction::FormatInput(predictionGraphs = projectedGraph, 
                                                     coregulationGraph = coreg.r2,
                                                     inputData = inputData, 
                                                     stype.class = "numeric",
                                                     stype = "age",
                                                     edgeTypeList = c("shared.outcome.analyte", "shared.independent.analyte"),
                                                     metaFeatures = metaFeatures,
                                                     modelProperties = myres.r2,
                                                     outcome = 1,
                                                     independent.var.type = 2)
modelResults <- MultiOmicsGraphPrediction::InitializeGraphLearningModel(modelInput = modelInput, learningRate = 0.2)
pairsPredAll <- MultiOmicsGraphPrediction::ObtainSubgraphNeighborhoods(modelInput = modelResults@model.input, percentOverlapCutoff = 50)

propagatedGraph <- MultiOmicsGraphPrediction::DoSignificancePropagation(pairs = pairsPredAll, modelResults = modelResults,
                                               verbose = TRUE, makePlots = FALSE, pruningMethod = "error.t.test", includeVarianceTest = TRUE,
                                               modelRetention = "stringent")
print(propagatedGraph)
print(MultiOmicsGraphPrediction::CompositePrediction(modelResults = modelResults, pairs = propagatedGraph[[1]]))
```

# Lenient Model Retention
In this example, we use the t-score of the predicted values to determine whether
or not to keep each model. We use a lenient model retention strategy, keeping
models that neither improve nor reduce the score.

The M2-based predictors are grouped together with G4 predictors in neighborhood 1.
In neighborhood 1, all predictors are removed except (M2, [G4, G6, G8]), the exact predictors.

The M4-based predictors are grouped together in neighborhood 2, along with the G7 predictors.
In neighborhood 2, all predictors are removed except (M4, [G4, G6, G8, G1, G11]) and (M3, G7).

The M3-based predictors are grouped together in neighborhood 3.
In neighborhood 3, all predictors are removed except (M3, [G6, G8, G11]) and (M6, G3).

The M1-based predictors are grouped together with G4 predictors in neighborhood 4.
In neighborhood 4, all predictors are removed except (M2, G4) and (M1, [G4, G6, G8]).

In the second iteration, neighborhoods 1 and 4 are combined to create the new neighborhood 1, and nothing is removed
(because they are identical). Nothing is removed from the other neighborhoods.

In the third iteration, neighborhoods 1 and 2 are combined to create the new neighborhood 1,
but neighborhood 2 is removed because both contain exact predictors. Neighborhood
3 becomes neighborhood 2.

In the fourth iteration, neighborhoods 1 and 2 are combined to create the new neighborhood 1,
but neighborhood 2 is removed.

The single pair (M2, G4) gives an exact prediction for the entire data set as expected.
```{r}
modelInput <- MultiOmicsGraphPrediction::FormatInput(predictionGraphs = projectedGraph, 
                                                     coregulationGraph = coreg.r2,
                                                     inputData = inputData, 
                                                     stype.class = "numeric",
                                                     stype = "age",
                                                     edgeTypeList = c("shared.outcome.analyte", "shared.independent.analyte"),
                                                     metaFeatures = metaFeatures,
                                                     modelProperties = myres.r2,
                                                     outcome = 1,
                                                     independent.var.type = 2)
modelResults <- MultiOmicsGraphPrediction::InitializeGraphLearningModel(modelInput = modelInput, learningRate = 0.2)
pairsPredAll <- MultiOmicsGraphPrediction::ObtainSubgraphNeighborhoods(modelInput = modelResults@model.input, percentOverlapCutoff = 50)

propagatedGraph <- MultiOmicsGraphPrediction::DoSignificancePropagation(pairs = pairsPredAll, modelResults = modelResults,
                                               verbose = TRUE, makePlots = FALSE, pruningMethod = "error.t.test", includeVarianceTest = TRUE,
                                               modelRetention = "lenient")
print(propagatedGraph)
print(MultiOmicsGraphPrediction::CompositePrediction(modelResults = modelResults, pairs = propagatedGraph[[1]]))
```

# Learn Weights.
Because the final predictors are exact, there is no need to adjust the weights so that
other models contribute more to the final prediction. Therefore, the optimization
converges immediately and returns the same set of predictors as the first iteration.
```{r}
optimalModel <- MultiOmicsGraphPrediction::OptimizeMetaFeatureCombo(modelResults = modelResults,pruningMethod = "error.t.test", includeVarianceTest = TRUE, verbose = TRUE,
                                                                    modelRetention = "stringent")
```

# Test Performance Using Leave-One-Out Cross-Validation
To perform leave-one-out cross-validation, we need to perform the following steps 6 times
(once for each sample):
1. Split the data into the training set (all samples except the one being left out)
and the testing set (the sample being left out).
2. Run IntLIM, create co-regulation graph, and run individual node prediction on
the training data.
3. Compute metafeatures on the training data.
4. Optimize the training data model.
5. Compute metafeatures on the testing data.
6. Do prediction for the testing data using the computed metafeatures on the testing data
and the subgraph and metafeature weights learned on the training data.

When we run cross-validation, we obtain (M2, G4) or another exact pair for each of
the cross-validations.
```{r}
for(sample in rownames(inputData@sampleMetaData)){
  print(sample)
  # Split into training and testing data.
  data <- MultiOmicsGraphPrediction::SplitTrainingAndTesting(inputData = inputData, testingSamples = sample)
  
  # Run prediction.
  modelResults.cv <- DoModelSetup(inputData = data$training,
                                  stype = "age",
                                  outcomeType = 1,
                                  independentVarType = 2,
                                  continuous = TRUE,
                                  metaFeatureList = c("pdf","interactionpval", "interactioncoef", "analytecoef", "localerr"),
                                 modelStats = myres.r2.cv,
                                  learningRate = 0.2)
  optimalModel.cv <- MultiOmicsGraphPrediction::OptimizeMetaFeatureCombo(modelResults = modelResults.cv,
                                                                   pruningMethod = "error.t.test", includeVarianceTest = TRUE, verbose = FALSE)

  pred.cv.test <- MultiOmicsGraphPrediction::RunPairwisePrediction(inputResults = myres.r2.cv,
                                                         inputData = data$testing,
                                                         stype = "age",
                                                         independentVarType = 2,
                                                         outcomeType = 1)

  # Get metafeatures for testing.
  metafeaturesTest <- MultiOmicsGraphPrediction::GetTestMetaFeatures(predictionsTrain = pred.cv,
                                                                  predictionsTest = pred.cv.test,
                                                                 stype = "age",
                                                                 inputDataTrain = data$training,
                                                                  inputDataTest = data$testing,
                                                                 metaFeatureList = c("pdf",
                                                                                     "interactionpval", "interactioncoef", "analytecoef", "localerr"),
                                                                 k = 2, eigStep = 1,
                                                                 modelStats = myres.r2.cv,
                                                                 colIdInd = "databaseId",
                                                                 colIdOut = "databaseId")

  # Predict testing values.
  predictions <- PredictTesting(inputData = data$testing, metafeatures = metafeaturesTest, model = optimalModel.cv)
  print(optimalModel.cv@pairs)
  print(paste(sample, predictions, data$testing@sampleMetaData$age))
}
```
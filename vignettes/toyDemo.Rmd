
---
title: "Ensemble Toy Demo"
author: "Tara Eicher"
date: "2/22/2022"
output: rmarkdown::html_document
vignette: >
  %\VignetteIndexEntry{IntLIM:  Integration through Linear Modeling}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---
# Set up.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
result_dir <- "~\\Ensemble_toy_vignette_results"
dir.create(result_dir)
```

# Install the packages.
```{r eval = FALSE}
if(!require("devtools")){
  install.packages("devtools")
}
library("devtools")
if(!require("MultiOmicsGraphPrediction")){
  install_github("ncats/MultiOmicsGraphPrediction")
}
library(MultiOmicsGraphPrediction)
if(!require("IntLIM")){
  install_github("ncats/IntLIM")
}
library(IntLIM)
```

# Import Toy data files.
```{r}
dir <- system.file("extdata", package="MultiOmicsGraphPrediction", mustWork=TRUE)
csvfile <- file.path(dir, "toyinput.csv")
inputData <- IntLIM::ReadData(csvfile)
```

# Run IntLIM
```{r}
myres <- IntLIM::RunIntLim(inputData = inputData,stype="age",
                                 save.covar.pvals = TRUE, 
                                 outcome = 1, 
                                 independent.var.type = 2, 
                                 continuous = TRUE)
```

# Filter Results
```{r}
myres.sig <- IntLIM::ProcessResults(inputResults = myres, inputData = inputData, 
                                       pvalcutoff = 0.20, )
IntLIM::OutputResults(inputResults=myres.sig,filename=paste(result_dir,
                                                                    "toyDataResults.csv"
                                                                    , sep = "/"))
```

# Create Co-Regulation Graph
In a co-regulation graph, nodes are analytes (genes and metabolites) and edges indicate
a significant phenotype-dependent association between the analytes.
```{r}
# Build graph.
coreg <- MultiOmicsGraphPrediction::BuildCoRegulationGraph(myres.sig)
PlotCoRegulationGraph(coreg, "Toy Data Graph", saveInFile = NULL, vertices = NULL,truncateTo = 4)
```

# Run Pairwise Prediction.
```{r}
# Run pairwise prediction.
pred <- MultiOmicsGraphPrediction::RunPairwisePrediction(inputResults = myres.sig, 
                                                         inputData = inputData,
                                                         stype = "age")
```

## Project Predictions
```{r plot graph}
# Project graph.
projectedGraph <- MultiOmicsGraphPrediction::ProjectPredictionsOntoGraph(coRegulationGraph = coreg,
                                                                         predictions = pred)
PlotGraphPredictions(projectedGraph, inputData, saveInDir = NULL, 
                                 vertices = NULL, truncateTo = 4, includeLabels = TRUE,
                                 cutoffs = NULL, vertexSize = 10)
```

## Create Model Input
```{r model input}
# Create input.
modelInput <- MultiOmicsGraphPrediction::FormatInput(predictionGraphs = projectedGraph, 
                                                     coregulationGraph = coreg,
                   inputData = inputData, stype.class = "numeric", stype = "age",
                   edgeTypeList = c("shared.outcome.analyte", "shared.independent.analyte"))
saveRDS(modelInput,file=paste(result_dir, paste0("modelInput.RDS"), sep = "\\"))
PlotPredictionDendrogram(modelInput, hierarchicalClustering, sampleIndex, 
                                     predictionLimits)
MultiOmicsGraphPrediction::PlotLineGraph(modelInput = modelInput, stype = "age", cutoffs = c(0,100))
```

## Compute Importance Metrics.
```{r importance}
MultiOmicsGraphPrediction::PlotSubspaceClusteringDendrogram(inputData = inputData, eigStep = 1)
MultiOmicsGraphPrediction::PlotSubspaceClusteringHeatmap(inputData = inputData, eigStep = 1)
importance <- MultiOmicsGraphPrediction::GetAllImportanceMetrics(predictions = pred, 
                                                                 modelInput = modelInput,
                                      inputData = inputData, metricList = c("pdf", 
                                                                            "localerr"),
                                      k = 2, eigStep = 1)
starting_weights <- lapply(1:length(importance), function(i){
  imp <- importance[[i]]
  nm <- names(importance)[i]
  sum_over <- as.data.frame(rowSums(imp))
  rownames(sum_over) <- rownames(imp)
  colnames(sum_over) <- nm
  return(sum_over)
})
starting_weights_all <- do.call(cbind,starting_weights)
```

## Calculate information gain for when all terms are included in a composite predictor.
```{r}
CompositePrediction <- function(pairs, covariates, weights, analyte1Vals, analyte2Vals){
  # Analyte 1
  weighted_a1 <- rep(0, ncol(weights))
  for(pair in pairs){
    weighted_a1 <- weighted_a1 + weights[pair,] * analyte1Vals[strsplit(pair, "__")[[1]][2],]
  }

  # beta0
  weighted_sum_b0 <- rep(0, ncol(weights))
  for(pair in pairs){
    weighted_sum_b0 <- weighted_sum_b0 + weights[pair,] * rep(covariates[pair,"(Intercept)"], ncol(weights))
  }
  
  # beta1
  weighted_sum_b1 <- rep(0, ncol(weights))
  for(pair in pairs){
    weighted_sum_b1 <- weighted_sum_b1 + weights[pair,] * rep(covariates[pair, "a"], ncol(weights)) * 
                                                                analyte2Vals[strsplit(pair, "__")[[1]][1],]
  }
  
  # beta2
  weighted_sum_b2 <- rep(0, ncol(weights))
  for(pair in pairs){
    weighted_sum_b2 <- weighted_sum_b2 + weights[pair,] * rep(covariates[pair, "type"], ncol(weights))
  }
  
  # beta3
  weighted_sum_b3 <- rep(0, ncol(weights))
  for(pair in pairs){
    weighted_sum_b3 <- weighted_sum_b3 + weights[pair,] * rep(covariates[pair, "a:type"], ncol(weights))* 
                                                                analyte2Vals[strsplit(pair, "__")[[1]][1],]
  }
  
  # Final value.
  final_val <- (weighted_a1 - weighted_sum_b0 - weighted_sum_b1) / (weighted_sum_b2 + weighted_sum_b3)
  return(final_val)
}

# Leave-one-out composite prediction
CompositePredictionLOO <- function(pairs, covariates, weights, analyte1Vals, analyte2Vals){
  removePairPred <- lapply(pairs, function(pair){
    return(CompositePrediction(setdiff(pairs, pair), covariates, weights, analyte1Vals, analyte2Vals))
  })
  return(removePairPred)
}
```

```{r}
# Information gain
ComputeInfoGain <- function(originalPred, trueVal){
  midrange <- (max(trueVal) - min(trueVal)) / 2
  
  # Compute original entropy.
  originalProb <- length(which(trueVal > midrange) == TRUE) / length(trueVal)
  originalEntropy <- -1 * (originalProb * log2(originalProb) + (1 - originalProb) * log2(1 - originalProb))

  # Compute entropy given prediction.
  predGreaterProb <- length(which(originalPred > midrange)) / length(originalPred)
  origGreaterPredGreaterProb <- length(intersect(which(trueVal > midrange), which(originalPred > midrange))) / 
    length(which(originalPred > midrange))
  origGreaterPredGreaterTerm <- -1 * origGreaterPredGreaterProb * log2(origGreaterPredGreaterProb) * predGreaterProb
  if(is.nan(origGreaterPredGreaterTerm) == TRUE){
    origGreaterPredGreaterTerm <- 0
  }
  
  origGreaterPredLessProb <- length(intersect(which(trueVal > midrange), which(originalPred <= midrange))) / 
    length(which(originalPred <= midrange))
  origGreaterPredLessTerm <- -1 * origGreaterPredLessProb * log2(origGreaterPredLessProb) * (1 - predGreaterProb)
  if(is.nan(origGreaterPredLessTerm) == TRUE){
    origGreaterPredLessTerm <- 0
  }
  
  origLessPredGreaterProb <- length(intersect(which(trueVal <= midrange), which(originalPred > midrange))) /
    length(which(originalPred > midrange))
  origLessPredGreaterTerm <- -1 * origLessPredGreaterProb * log2(origLessPredGreaterProb) * predGreaterProb
  if(is.nan(origLessPredGreaterTerm) == TRUE){
    origLessPredGreaterTerm <- 0
  }
  
  origLessPredLessProb <- length(intersect(which(trueVal <= midrange), which(originalPred <= midrange))) /
    length(which(originalPred <= midrange))
  origLessPredLessTerm <- -1 * origLessPredLessProb * log2(origLessPredLessProb) * (1 - predGreaterProb)
  if(is.nan(origLessPredLessTerm) == TRUE){
    origLessPredLessTerm <- 0
  }
  
  conditionalEntropy <- origGreaterPredGreaterTerm + origGreaterPredLessTerm + origLessPredGreaterTerm + origLessPredLessTerm
  originalIG <- originalEntropy - conditionalEntropy
  return(originalIG)
}
```

```{r}
pairsPredAll <- list(list("Gene4__Metab2", "Gene6__Metab2", "Gene8__Metab2"),
                     list("Gene11__Metab4", "Gene5__Metab4", "Gene7__Metab4", "Gene11__Metab1", "Gene11__Metab3"),
                     list("Gene11__Metab4", "Gene5__Metab4", "Gene7__Metab4", "Gene5__Metab1", "Gene5__Metab3"),
                     list("Gene11__Metab4", "Gene5__Metab4", "Gene7__Metab4", "Gene7__Metab1", "Gene7__Metab3"),
                     list("Gene11__Metab1", "Gene5__Metab1", "Gene7__Metab1", "Gene7__Metab4", "Gene7__Metab3"),
                     list("Gene11__Metab1", "Gene5__Metab1", "Gene7__Metab1", "Gene11__Metab4", "Gene11__Metab3"),
                     list("Gene11__Metab1", "Gene5__Metab1", "Gene7__Metab1", "Gene5__Metab4", "Gene5__Metab3"),
                     list("Gene11__Metab3", "Gene5__Metab3", "Gene7__Metab3", "Gene7__Metab4", "Gene7__Metab1"),
                     list("Gene11__Metab3", "Gene5__Metab3", "Gene7__Metab3", "Gene11__Metab4", "Gene11__Metab1"),
                     list("Gene11__Metab3", "Gene5__Metab3", "Gene7__Metab3", "Gene5__Metab4", "Gene5__Metab1"))
importantPredictors <- lapply(pairsPredAll, function(pairsPred){
  pred1 <- CompositePrediction(pairsPred, myres@covariate.coefficients, starting_weights_all,
                             inputData@analyteType1, inputData@analyteType2)

  # Prune the pairs.
  removePairPred <- CompositePredictionLOO(pairsPred, myres@covariate.coefficients, starting_weights_all,
                             inputData@analyteType1, inputData@analyteType2)
  infoGainOriginal <- ComputeInfoGain(unlist(pred1), inputData@sampleMetaData[,myres@stype])
  infoGainsLOO <- lapply(removePairPred, function(p){
    return(ComputeInfoGain(unlist(p), inputData@sampleMetaData[,myres@stype]))
  })
  informativePairs <- unlist(pairsPred[which(infoGainsLOO < infoGainsOriginal)])
  if(length(which(infoGainsLOO < infoGainOriginal))==0){
    informativePairs <- unlist(pairsPred[which(infoGainsLOO == infoGainsOriginal)])[1]
  }

  # For each pair that was pruned, see if it functions better than the full
  # predictor as an "orphan" pair.
  orphans <- setdiff(unlist(pairsPred), informativePairs)
  importantOrphans <- unlist(lapply(1:length(orphans), function(orphan){
    orphanPred <- as.data.frame(t(as.data.frame(pred[,orphan])))
    orphanInfoGain <- ComputeInfoGain(orphanPred, inputData@sampleMetaData[,myres@stype])
    retval <- NULL
    if(orphanInfoGain > infoGainOriginal){
      retval <- orphan
    }
    return(retval)
  }))
  return(list(modelPairs = informativePairs, orphans = importantOrphans))
})
print(importantPredictors)
```

# Merge Predictors (Second Layer)
```{r}
# Compute table of pair overlaps.
pairCounts <- table(unlist(pairsPredAll))
predictorsContaining <- pairCounts[order(-pairCounts)]

# Loop through and group composite predictors.
belongsTo <- rep(0, length(pairsPredAll))
compositePredictors <- list()
predictorIdx <- 1
for(pair in names(predictorsContaining)){
  # For each pair, find the predictors containing it.
  listContainsPair <- unlist(lapply(1:length(pairsPredAll), function(i){
    composite <- pairsPredAll[[i]]
    containsPair <- FALSE
    if(pair %in% composite){
      containsPair <- TRUE
    }
    return(containsPair)
  }))
  # If the predictors containing it have not been assigned, assign them.
  if(max(belongsTo[which(listContainsPair == TRUE)]) == 0){
    belongsTo[which(listContainsPair == TRUE)] <- predictorIdx
    predictorIdx <- predictorIdx + 1
  }
  # If some of the predictors have already been assigned, merge with them.
  else{
    belongsTo[which(listContainsPair == TRUE)] <- max(belongsTo[which(listContainsPair == TRUE)])
  }
  #compositePredictors[[length(compositePredictors)+1]] <- which(listContainsPair == TRUE)
}
print(belongsTo)
```